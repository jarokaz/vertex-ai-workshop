{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and deploying a tabular model using Vertex AutoML - Part 2.\n",
    "\n",
    "![Training pipeline](../images/automl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform_v1beta1 import types\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure GCP settings\n",
    "\n",
    "*Before running the notebook make sure to follow the repo's README file to install the pre-requisites and configure GCP authentication.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  jk-vertex-workshop\n"
     ]
    }
   ],
   "source": [
    "PREFIX = 'jk1'\n",
    "\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT = shell_output[0]\n",
    "print(\"Project ID: \", PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLTabularTrainingJob projects/910094146258/locations/us-central1/trainingPipelines/3144466915997515776 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = f'gs://{PREFIX}-bucket'\n",
    "VERTEX_SA = f'training-sa@{PROJECT}.iam.gserviceaccount.com'\n",
    "BQ_DATASET_NAME = f'{PREFIX}_dataset' \n",
    "BQ_TABLE_NAME = 'features'\n",
    "BQ_LOCATION = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tabular dataset in Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new dataset.\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Creating TabularDataset\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:Create TabularDataset backing LRO: projects/910094146258/locations/us-central1/datasets/4162953332899446784/operations/157533902859141120\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:TabularDataset created. Resource name: projects/910094146258/locations/us-central1/datasets/4162953332899446784\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:To use this TabularDataset in another session:\n",
      "INFO:google.cloud.aiplatform.datasets.dataset:ds = aiplatform.TabularDataset('projects/910094146258/locations/us-central1/datasets/4162953332899446784')\n"
     ]
    }
   ],
   "source": [
    "display_name = f'{PREFIX} Chicago taxi trips'\n",
    "bq_source_uri = f'bq://{PROJECT}.{BQ_DATASET_NAME}.{BQ_TABLE_NAME}'\n",
    "\n",
    "filter = f'display_name=\"{display_name}\"'\n",
    "\n",
    "dataset = vertex_ai.TabularDataset.list(filter=filter)\n",
    "if not dataset:\n",
    "    print(\"Creating a new dataset.\")\n",
    "    dataset = vertex_ai.TabularDataset.create(\n",
    "        display_name=display_name, bq_source=bq_source_uri,\n",
    "    )\n",
    "\n",
    "    dataset.wait()\n",
    "else:\n",
    "    print(\"Using existing dataset: \", dataset[0].resource_name)\n",
    "    dataset = vertex_ai.TabularDataset(dataset_name=dataset[0].resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching an AutoML training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.training_jobs:View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/3144466915997515776?project=910094146258\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLTabularTrainingJob projects/910094146258/locations/us-central1/trainingPipelines/3144466915997515776 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLTabularTrainingJob projects/910094146258/locations/us-central1/trainingPipelines/3144466915997515776 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.training_jobs:AutoMLTabularTrainingJob projects/910094146258/locations/us-central1/trainingPipelines/3144466915997515776 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "display_name = f'{PREFIX} Chicago Taxi classifier training'\n",
    "model_display_name = 'Chicago Taxi classifier'\n",
    "target_column = 'tip_bin'\n",
    "optimization_prediction_type = 'classification'\n",
    "optimization_objective = 'maximize-recall-at-precision'\n",
    "optimization_objective_precision_value = 0.7\n",
    "split_column = 'data_split'\n",
    "budget_milli_node_hours = 1000\n",
    "\n",
    "column_transformations = [\n",
    "    {'categorical': {'column_name': 'trip_month'}},\n",
    "    {'categorical': {'column_name': 'trip_day'}},\n",
    "    {'categorical': {'column_name': 'trip_day_of_week'}},\n",
    "    {'categorical': {'column_name': 'trip_hour'}},\n",
    "    {'categorical': {'column_name': 'payment_type'}},\n",
    "    {'categorical': {'column_name': 'pickup_grid'}},\n",
    "    {'categorical': {'column_name': 'dropoff_grid'}},\n",
    "    {'numeric': {'column_name': 'trip_seconds'}},\n",
    "    {'numeric': {'column_name': 'euclidean'}},\n",
    "    {'numeric': {'column_name': 'trip_miles'}},\n",
    "]\n",
    "\n",
    "job = vertex_ai.AutoMLTabularTrainingJob(\n",
    "    display_name=display_name,\n",
    "    optimization_prediction_type=optimization_prediction_type,\n",
    "    optimization_objective=optimization_objective,\n",
    "    optimization_objective_precision_value=optimization_objective_precision_value,\n",
    "    column_transformations=column_transformations,\n",
    ")\n",
    "\n",
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    target_column=target_column,\n",
    "    budget_milli_node_hours=budget_milli_node_hours,\n",
    "    model_display_name=model_display_name,\n",
    "    predefined_split_column_name=split_column,\n",
    "    sync=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI_Platform_(Unified)_SDK_AutoML_Image_Classification_Training.ipynb",
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-5.m73",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m73"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
